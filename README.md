
## 开源支持
- [rapidjson](https://github.com/Tencent/rapidjson)
- [tortellini](https://github.com/Qix-/tortellini)
- 在原来的 tortellini 中添加了一些项目需求的自定义方法支持。

## 项目说明
- 通过配置进行连接、监听或子进程启动，守护进程会对子进程进行守护；
- 支持子进程之间，子进程与守护进程之间的通信；
- 使用者可以通过接口设置自己在子进程中要运行的服务(函数实现)；
- 如果作为服务器，其本质实现仍然是接收到外界(客户端消息)后，交给子进程处理，即实质上子进程是服务器；

## 项目管理、编译及运行环境
- 项目管理工具支持
    + [x] make (为加快编译，会生成一个静态库。建议调试时使用)
    + [x] cmake (源文件编译)
- 最小编译配置支持
    + [x] GNU gcc/g++ 4.8.4
    + [x] cmake 3.0.2
- 运行过的机器环境
    + [x] Kylin 4.0.2 (aarch64)
    + [x] Ubuntu 14.04 (x86_64)
    + [x] RHEL 7.5 (x86_64)
    + [x] Debian 9.8 (x86_64)

## 问题处理
- [x] 编译警告处理
- [x] 内存泄漏处理
- [ ] 其他处理

## 功能概述
- [x] 消息定义
- [x] 消息序列化反序列化
- [x] 消息支持CRC校验
- [x] 事件反应器
- [x] 事件回调器
- [x] 定时器
- [x] 信号处理
- [x] 心跳
- [x] 服务可配置及扩展
- [x] 服务分离与自治
- [x] 守护子进程
- [x] 进程队列
- [x] 线程队列
- [x] 子进程杀灭
- [x] 僵尸进程处理
- [x] 优雅退出
- [x] 线程安全的日志模块
- [x] 定制化客户端扩展
- [x] 简易TCC
- [x] 示例

## 功能设计详述
- 消息定义、序列化和反序列化
    + 每种消息包括消息ID及消息结构类，消息ID在 bic_type 文件中定义，与消息ID对应的消息结构类在 bic 文件中定义。
    + 每种消息结构类中定义对应消息ID所绑定的各类数据成员，消息结构类定义统一的序列化和反序列化方法，对成员进行网络传输。
    + 为了适应TCP传输要求，从应用层角度看，整个消息传输采用[自定义消息头+消息体]组合方式。自定义消息头内容包括版本号、消息体长度、消息校验值等内容。而消息体又分成了两部分，分别是消息头和有效荷载体。消息头主要定义了消息的通备属性，如消息流向、类型和生成时间等，而有效荷载体则定义了具体的业务内容。
    + 整个消息包结构如下(json示意)
        ```json
        Packet: {
            NegoHeader: {
                // ...
            },
            BIC_MESSAGE: {
                BIC_HEADER : {
                    // ...
                },
                BIC_PAYLOAD : {
                    // ...
                }
            }
        }
        ```
- 事件反应器
    + 事件反应类型包括读、写、连接、关闭或异常等；
    + Linux下，常见的描述符大致有四类，分别是TCP套接字、管道符、UDP套接字、普通文件套接字。其中前两种是面向连接的描述符，后两种是面向非连接的描述符，本处理暂只支持面向连接的描述符；
    + 通过 Linux epoll 多路复用模型对描述符事件进行处理；
    + 事件反应器只作简单的读、写及连接与关闭等，具体的业务处理由事件回调器完成；
- 事件回调器
    + 主要针对事件反应器的读写事件及因循环发生的定时器事件进行回调处理。
- 定时器
    + 简单的通过 epoll 的超时来实现一个伪定时器；
- 信号处理
    + 对一些可能会影响到进程启动或进程运行的信号进行忽略处理；
    + 利用 SIGALRM 信号的定时机制；
    + 重定义 SIGINT 的信号处理句柄；
- 心跳
    + 子进程定时向守护进程发送心跳，后者以此作为根据来判断子进程服务连接是否丢失；
    + 心跳在定时器回调事件中实现。
- 服务可配置及扩展
    + 将要启动的子进程服务按要求存为一份配置，程序启动后作为守护进程，同时按照配置上的描述启动(fork)相应的子进程服务；
    + 程序会对配置进行一定的检测，如果不符合要求则退出。理论上来说，可以启动的子进程"无限"(取决于Linux限制)，而守护进程只能有一个。
- 服务分离与自治
    + 各子进程服务之间相互独立，子进程之间、子进程与远程其他端之间的通信通过守护进程作中介传输；
    + 系统通过服务的名称，在内部自己计算出一个整型id来标识此服务。每个子进程服务都保存有一份已开启服务的id列表，将消息发送给对应的id就可以完成进程间的通信。
    + 每个服务松耦合，能够对自己的逻辑服务完全负责，且不会对其他服务造成影响。
- 守护子进程
    + 通过检测心跳来对子进程服务进行守护。在判断某个子进程连接丢失后，守护进程会重新拉起该子进程。
- 进程队列
    + 进程队列映射表由守护进程维护，因为子进程之间的通信要在守护进程中作中转，可以看作是一个中介者模式。这样可以减少通信的复杂度。
    + 守护进程收到某个子进程的通信时，判断要发送到哪个目标子进程，并将此消息写入目标进程队列中等待发送。
- 线程队列
    + 每个子进程中，用户业务线程与IO线程分离，所以需要设置线程队列用于消息的生产与消费。
- 子进程杀灭
    + 可以通过下发消息的方式杀死某个子进程(不过随后守护进程又会将该进程重新拉起)；
    + 进程杀灭一般很少使用，目前只在测试情况下使用；
- 僵尸进程处理
    + 某个子进程在无法执行服务后，可能仍会作为僵尸进程存在于系统中，这个时候守护进程有义务将此僵尸进程杀掉。
- 优雅退出
    + 具体就是 Ctrl+C 时确保所有的堆栈都得到销毁，并且没有内存泄漏。
- 线程安全的日志模块
    + 经得起考验
- 定制化客户端扩展
    + 为了方便对每个描述符的维护和管理，并适时记录一些信息，将描述符封装入 EClient 结构中；
    + 可以为 EClient 添加一些虚函数，如数据库处理函数或序列化反序列化函数，以便将 EClient 状态数据写入本地数据库或上传至远端服务器；

## 特点
1. 配置驱动服务。用户服务在子进程中运行，而子进程通过配置来实现应该启动什么类型的服务。这是最大的特点。
2. 服务可配置。如果需要增加一个服务进程，就在配置里写上就好，而不需要增加任何代码。
3. 服务自治。提供了接口文件，使用者可以在这里编写具体的服务实现。
4. 进程间通信。服务通过框架内部自己根据服务名称计算出的ID进行标识。这样各子服务之间、子服务与远程服务之间可以很容易知道自己的通信对象是谁，简单方便。
5. 各服务之间的启动顺序可以由使用者通过消息流的传递顺序进行控制，一定程度上实现了TCC事务机制。
6. 各服务内部不会创建大量线程及过度使用锁。
7. 守护进程(父进程)只进行简单的连接、监听和数据传递，并不会进行具体的服务处理。这让守护进程的生存能力大大提高，近而各具体服务的持续服务能力增强，整个系统的健壮性因此提升。

## 关于配置驱动服务
- 实现配置驱动服务要对两个定义进行处理: 系统服务定义和用户服务定义。
- 系统服务定义。前期对其定义不清晰导致虽然对事件回调进行了模块化分离，但需要定义每个系统服务的事件回调，实现上有些冗余。后来将系统服务归类为守护进程、子进程、本地连接和本地监听共四种，其中本地连接或本地监听与守护进程共享一个进程，子进程通过守护进程创建。同时参考监听进程接收连接之后fork子进程处理的实现，将本地连接和本地监听的事件回调下放至子进程中进行，这样一共就只需要定义两个事件回调模块(守护和子进程)，不仅提高了守护进程的稳定性，也可以更灵活地进行后续要说的用户服务扩展。
- 用户服务定义。前期需要使用者自己添加用户服务，在源文件中涉及到到多处改动，使用很不方便。将要启动的用户服务写入到.ini配置中，程序运行时首先读取该配置，通过服务名称计算每个服务的哈希，转换为一个整型作为标识该服务的id，并通过配置中的key-value项确定该用户服务属于哪一种系统服务及服务的其他属性。这样使用者不仅可以只通过修改配置灵活地添加、删除或修改服务，而且也可以通过自动搜索id实现各服务间的通信。

## 关于消息队列
- 消息队列机制
    + 进程间的读写是异步的，如果读端较慢而写端较快，写端可能会:
        1.读端还未开始读取，写端又重写缓冲区，覆盖之前的数据，造成读端读取消息有遗漏；
        2.读端仅读取一部分数据，写端缓冲区仍有另外一部分数据，此时新消息重写写端缓冲区，造成
          读端读取消息会拼错；
    + 为了避免上述情况，采用消息队列机制。
- 消息延迟计算
    + 理想情况下，写端写入一个消息到队列后，读端会立即从队列中取出并处理，消息并不会在队列中
      "停留"太长时间。实际情况可能是，一个消息加入到队列后，读端还未处理，此时另外的消息也加
      入到队列中，这种情况下，需要对消息延迟进行观察，以判断延迟程度，进而估计系统性能；
    + 理想情况下，消息流空闲时，队列多数时间为空，消息队列最大长度不会超过1；消息流繁忙时，
      队列最大长度也不会超过1。所以可以简单的通过消息队列长度来判断消息延迟；
        1. 消息流空闲时: 消息延迟占比 = 消息队列长度为1 / (消息队列长度为0 + 消息队列长度为1)
        2. 消息流繁忙时: 消息延迟 = 消息队列长度 - 1
      消息流繁忙时，可自定义一个低延迟标准(比如 3以下)，之后据此计算一段时间内超过该标准的占比。
    + 主要是对消息流繁忙时的消息延迟进行统计；

## 关于大文件传输
- 文件采用分块传输方式，块与块之间顺序性独立发送(放入队列后立即发送)，与将整个文件切片放入队列后
  统一发送相比，优点如下:
    + 减小传输队列，节省内存；
    + 收发异步，节省时间；
    + 有效减少校验错误；
    + 块与块之间独立发送，某块出错后从出错块开始重传，较为节省资源和时间(暂未实现，需要微调结构)；
- 目前只支持并行发送一个文件，可根据需要实现支持多文件并行发送，但目前还无必要，也暂未实现；
- 分块传输时，因为 tcp 已经进行了确认机制，所以这里收端不再对每块数据向发端发送确认，只在校验出
  错时发送重传消息，以提高效率；
- 虽然没有实现重传，但目前为止对一些文件的传输测试(10M, 20M, 50M, 100M, 300M)暂未出错过；

# 使用说明
- 使用时只需要对三个部分进行添加或修改:配置，自定义服务，main函数。